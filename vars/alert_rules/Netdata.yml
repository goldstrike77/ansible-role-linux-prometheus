---
prometheus_netdata_alert_rules:
# Netdata performance and health monitoring for system
  - alert: node_PS_Load
    expr: 'sum(netdata_system_load_load_average{dimension="load5"})by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)>count(netdata_cpu_cpu_percentage_average{dimension="idle"})by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: "Processor load has exceeded the threshold for more than 10m minutes."

  - alert: node_high_cpu_usage
    expr: 'avg(rate(netdata_cpu_cpu_percentage_average{dimension="idle"}[5m])) by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) > 90'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: 'Processor usage has exceeded the threshold with a value of {{ $value | printf "%.0f" }}%.'

  - alert: node_high_memory_usage
    expr: '100 / sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)(netdata_system_ram_MiB_average) * sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)(netdata_system_ram_MiB_average{dimension=~"free|cached|buffers"}) < 10'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Memory free has less than 10% with a value of {{ $value | printf "%.0f" }}%.'

  - alert: node_low_filesystem_space
    expr: '100 / sum(netdata_disk_space_GiB_average{family!~"/boot/efi|/run|/dev/shm|/dev"}) by (family,datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) * sum(netdata_disk_space_GiB_average{family!~"/boot/efi|/run|/dev/shm|/dev",dimension=~"avail|cached"}) by (family,datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) < 20'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Filesystem has less than 20% with a value of {{ $value | printf "%.0f" }}.'

  - alert: node_low_filesystem_space
    expr: '100 / sum(netdata_disk_space_GiB_average{family!~"/boot/efi|/run|/dev/shm|/dev"}) by (family,datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) * sum(netdata_disk_space_GiB_average{family!~"/boot/efi|/run|/dev/shm|/dev",dimension=~"avail|cached"}) by (family,datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) < 10'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: 'Filesystem has less than 10% with a value of {{ $value | printf "%.0f" }}.'

  - alert: node_Disc_Read
    expr: 'netdata_disk_await_milliseconds_operation_average{dimension="reads"} > 100'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Disk read latency > 100ms with a value of {{ $value }}.'

  - alert: node_root_filesystem_fill_rate_6h
    expr: 'predict_linear(netdata_disk_space_GiB_average{family!~"/boot/efi|/run|/dev/shm|/dev",dimension=~"avail|cached"}[1h], 6 * 3600) < 0'
    for: 60m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: "Container node filesystem is going to fill up in 6h."
