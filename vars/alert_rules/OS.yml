---
prometheus_os_alert_rules:
# Operating system
  - alert: node_Reboot
    expr: "(rate(node_boot_time_seconds[10m]) != 0) or (rate(windows_system_system_up_time[10m]) != 0)"
    for: 5m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: 'Reboots event detected recently.'
  - alert: node_PS_Load
    expr: "(node_load15 / count without (cpu, mode) (node_cpu_seconds_total{mode='system'})) > 5"
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Processor load has exceeded the threshold with a value of {{ $value | printf "%.0f" }}%.'
  - alert: node_CPU_usage
    expr: '((100 * (1 - avg by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)(irate(node_cpu_seconds_total{mode="idle"}[10m])))) > 90) or ((100 * (1 - avg by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)(irate(windows_cpu_time_total{mode="idle"}[10m])))) > 90)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Processor usage has exceeded the threshold with a value of {{ $value | printf "%.0f" }}%.'
  - alert: node_RAM_Usage
    expr: '((sum(node_memory_MemTotal_bytes)by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) - sum(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes )by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)) / (sum(node_memory_MemTotal_bytes)by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)) * 100 > 90) or ((sum(windows_cs_physical_memory_bytes)by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) - sum(windows_os_physical_memory_free_bytes)by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)) / (sum(windows_cs_physical_memory_bytes)by(datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>)) * 100 > 90)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Memory usage has exceeded the threshold with a value of {{ $value | printf "%.0f" }}%.'
  - alert: node_FS_Usage
    expr: '((node_filesystem_free_bytes{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} / node_filesystem_size_bytes{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} < 0.2) or (windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*"} / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*"} < 0.2)) * 100'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Filesystem has less than 20% with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_FS_Usage
    expr: '((node_filesystem_free_bytes{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} / node_filesystem_size_bytes{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} < 0.1) or (windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*"} / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*"} < 0.1)) * 100'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: 'Filesystem has less than 10% with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_FS_Space_Filling_Up
    expr: '( node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 40 and predict_linear(node_filesystem_avail_bytes{fstype!=""}[6h], 24*60*60) < 0 and node_filesystem_readonly{fstype!=""} == 0 )'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Filesystem is predicted to run out of space within the next 24 hours.'
  - alert: node_FS_Space_Filling_Up
    expr: '( node_filesystem_files_free{fstype!=""} / node_filesystem_files{fstype!=""} * 100 < 40 and predict_linear(node_filesystem_files_free{fstype!=""}[6h], 24*60*60) < 0 and node_filesystem_readonly{fstype!=""} == 0 )'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].critical >>
    annotations:
      description: 'Filesystem is predicted to run out of space within the next 4 hours.'
  - alert: node_FS_Inodes
    expr: 'node_filesystem_files_free{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} / node_filesystem_files{fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} * 100 < 10'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Filesystem inodes has less than 10% with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_Disc_Read
    expr: '(irate(node_disk_read_time_seconds_total{device!~"dm-.+"}[5m]) / irate(node_disk_reads_completed_total{device!~"dm-.+"}[5m])) * 1000 > 100'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Disk read latency > 100ms with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_Disc_Write 
    expr: '(irate(node_disk_write_time_seconds_total{device!~"dm-.+"}[5m]) / irate(node_disk_writes_completed_total{device!~"dm-.+"}[5m])) * 1000 > 100'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Disk write latency > 100ms with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_NIC_Receive
    expr: '(irate(node_network_receive_bytes_total{device!~"lo|docker.*"}[5m]) > 300000000) or (irate(windows_net_bytes_received_total[5m]) > 300000000)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: "{{ $labels.device }} has more than 300M receive."
  - alert: node_NIC_Transmit
    expr: '(irate(node_network_transmit_bytes_total{device!~"lo|docker.*"}[5m]) > 30000000) or (irate(windows_net_bytes_sent_total[5m]) > 30000000)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: "{{ $labels.device }} has more than 300M traffic."
  - alert: node_Service
    expr: '(node_systemd_unit_state{state="inactive"} == 1) or (windows_service_state{state="stopped"} == 1)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: "Service has been stoped."
  - alert: node_Disc_Read
    expr: '(sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) (irate(node_disk_read_bytes_total{device!~"dm-.+"}[5m])) / 1024 / 1024 > 50) or (sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) (irate(windows_logical_disk_read_bytes_total{volume!~"HarddiskVolume.*"}[5m])) / 1024 / 1024 > 50)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Disk is probably reading too much data with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_Disc_Write
    expr: '(sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) (irate(node_disk_written_bytes_total{device!~"dm-.+"}[5m])) / 1024 / 1024 > 50) or (sum by (datacenter,customer,environment,project,group,instance,service<< tags_key | default("") >>) (irate(windows_logical_disk_write_bytes_total{volume!~"HarddiskVolume.*"}[5m])) / 1024 / 1024 > 50)'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Disk is probably writing too much data with a value of {{ $value | printf "%.0f" }}.'
  - alert: node_OOM_detected
    expr: 'increase(node_vmstat_oom_kill[1h]) > 2'
    for: 1h
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Several OOM kills detected recently.'
  - alert: node_Clock_Skew_Detected
    expr: '( node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0 ) or ( node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0 ) or windows_time_computed_time_offset_seconds > 1'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Clock skew detected.'
  - alert: node_Clock_Not_Synchronising
    expr: 'min_over_time(node_timex_sync_status[5m]) == 0 or max_over_time(windows_time_ntp_client_time_source_count[10m]) == 0'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].high >>
    annotations:
      description: 'Clock not synchronising.'
  - alert: node_High_Number_Conntrack_Entries_Used
    expr: '(node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75'
    for: 10m
    labels:
      severity: << vars['prometheus_alert_incident_' + prometheus_alert_incident_levels_map].warning >>
    annotations:
      description: 'Number of conntrack are getting close to the limit.'
